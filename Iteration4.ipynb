{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('operations').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv('Dataset/integrate_data1.csv', inferSchema=True, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorAssembler_4a5583c5d0da87eba604\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(\n",
    "  inputCols=['year',\n",
    "             'month',\n",
    "             'day',\n",
    "             'hour',\n",
    "             'season',\n",
    "             'DEWP',\n",
    "             'HUMI',\n",
    "             'PRES',\n",
    "             'TEMP',\n",
    "             'Iws',\n",
    "             'precipitation',\n",
    "             'Iprec',\n",
    "             'cbwd_new'],\n",
    "              outputCol=\"features\")\n",
    "print(assembler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's transform the data. \n",
    "output = assembler.transform(df)\n",
    "# Let's import the string indexer (similar to the logistic regression exercises).\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer = StringIndexer(inputCol=\"Air Quality\", outputCol=\"AirQualityIndex\")\n",
    "output_fixed = indexer.fit(output).transform(output)\n",
    "# Let's select the two columns we want. Features (which contains vectors), and the predictor.\n",
    "final_data = output_fixed.select(\"features\",'AirQualityIndex')\n",
    "# Split the training and testing set.\n",
    "train_data,test_data = final_data.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier,GBTClassifier,RandomForestClassifier\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(labelCol='AirQualityIndex',featuresCol='features',\n",
    "                             impurity='entropy',maxBins=80,maxDepth=30)\n",
    "dtc_model = dtc.fit(train_data)\n",
    "dtc_predictions = dtc_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC\n",
      "0.7023005487547488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SparseVector(13, {0: 0.0764, 1: 0.0794, 2: 0.176, 3: 0.1387, 4: 0.0092, 5: 0.1257, 6: 0.057, 7: 0.1014, 8: 0.0562, 9: 0.1068, 10: 0.0102, 11: 0.0099, 12: 0.0531})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start off with binary classification.\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Note that the label column isn't named label, it's named PrivateIndex in this case.\n",
    "my_binary_eval = BinaryClassificationEvaluator(labelCol = 'AirQualityIndex')\n",
    "# This is the area under the curve. This indicates that the data is highly seperable.\n",
    "print(\"DTC\")\n",
    "print(my_binary_eval.evaluate(dtc_predictions))\n",
    "\n",
    "dtc_model.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !conda install --yes --prefix {sys.prefix} scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/mllib/evaluation.py:249: UserWarning: Deprecated in 2.0.0. Use accuracy.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use accuracy.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall = 0.7177131189382338\n",
      "F1 Score = 0.7177131189382338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/mllib/evaluation.py:262: UserWarning: Deprecated in 2.0.0. Use accuracy.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use accuracy.\")\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "# prediction1 = np.array(dtc_predictions.select('prediction').collect())\n",
    "# label = np.array(AirQualityIndex.select('AirQualityIndex').collect())\n",
    "\n",
    "results = dtc_predictions.select(['prediction', 'AirQualityIndex'])\n",
    "predictionAndLabels=results.rdd\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "# Overall statistics\n",
    "recall = metrics.recall()\n",
    "f1Score = metrics.fMeasure()\n",
    "print(\"Recall = %s\" % recall)\n",
    "print(\"F1 Score = %s\" % f1Score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $hadoop version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC\n",
      "0.5783792997689357\n",
      "+--------------------+---------------+--------------------+--------------------+----------+\n",
      "|            features|AirQualityIndex|       rawPrediction|         probability|prediction|\n",
      "+--------------------+---------------+--------------------+--------------------+----------+\n",
      "|[2011.0,12.0,29.0...|            1.0|[8.92805658106875...|[0.44640282905343...|       0.0|\n",
      "|[2011.0,12.0,29.0...|            1.0|[8.92805658106875...|[0.44640282905343...|       0.0|\n",
      "|[2011.0,12.0,29.0...|            0.0|[8.85040133672676...|[0.44252006683633...|       0.0|\n",
      "|[2011.0,12.0,29.0...|            0.0|[8.61963266360140...|[0.43098163318007...|       0.0|\n",
      "|[2011.0,12.0,29.0...|            3.0|[8.08344698140270...|[0.40417234907013...|       0.0|\n",
      "|[2011.0,12.0,29.0...|            2.0|[8.08344698140270...|[0.40417234907013...|       0.0|\n",
      "|[2011.0,12.0,29.0...|            0.0|[8.08344698140270...|[0.40417234907013...|       0.0|\n",
      "|[2011.0,12.0,31.0...|            2.0|[9.15347668625338...|[0.45767383431266...|       0.0|\n",
      "|[2011.0,12.0,31.0...|            2.0|[7.06656289584574...|[0.35332814479228...|       0.0|\n",
      "|[2011.0,12.0,31.0...|            2.0|[7.06194554700592...|[0.35309727735029...|       0.0|\n",
      "|[2011.0,12.0,31.0...|            2.0|[9.14771741494795...|[0.45738587074739...|       0.0|\n",
      "|[2012.0,1.0,1.0,2...|            0.0|[7.77270807652053...|[0.38863540382602...|       0.0|\n",
      "|[2012.0,1.0,2.0,5...|            0.0|[7.23018482285231...|[0.36150924114261...|       0.0|\n",
      "|[2012.0,1.0,2.0,9...|            2.0|[6.87336204620105...|[0.34366810231005...|       0.0|\n",
      "|[2012.0,1.0,2.0,1...|            2.0|[8.22026727440589...|[0.41101336372029...|       0.0|\n",
      "|[2012.0,1.0,2.0,1...|            0.0|[7.11879991570677...|[0.35593999578533...|       0.0|\n",
      "|[2012.0,1.0,2.0,1...|            0.0|[9.24409917199861...|[0.46220495859993...|       0.0|\n",
      "|[2012.0,1.0,2.0,1...|            0.0|[9.24409917199861...|[0.46220495859993...|       0.0|\n",
      "|[2012.0,1.0,2.0,1...|            0.0|[8.38652501470045...|[0.41932625073502...|       0.0|\n",
      "|[2012.0,1.0,3.0,6...|            0.0|[6.66195799737603...|[0.33309789986880...|       0.0|\n",
      "+--------------------+---------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(labelCol='AirQualityIndex',featuresCol='features',impurity='entropy'\n",
    "#                              ,maxBins=20,maxDepth=10\n",
    "                            )\n",
    "rfc_model = rfc.fit(train_data)\n",
    "rfc_predictions = rfc_model.transform(test_data)\n",
    "# RFC improves accuracy but also model complexity. RFC outperforms DTC in nearly every situation.\n",
    "print(\"RFC\")\n",
    "print(my_binary_eval.evaluate(rfc_predictions))\n",
    "\n",
    "rfc_predictions.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- season: integer (nullable = true)\n",
      " |-- DEWP: integer (nullable = true)\n",
      " |-- HUMI: double (nullable = true)\n",
      " |-- PRES: double (nullable = true)\n",
      " |-- TEMP: integer (nullable = true)\n",
      " |-- Iws: integer (nullable = true)\n",
      " |-- precipitation: double (nullable = true)\n",
      " |-- Iprec: double (nullable = true)\n",
      " |-- Air Quality: integer (nullable = true)\n",
      " |-- cbwd_new: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/mllib/evaluation.py:249: UserWarning: Deprecated in 2.0.0. Use accuracy.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use accuracy.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall = 0.530032329419772\n",
      "F1 Score = 0.530032329419772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/mllib/evaluation.py:262: UserWarning: Deprecated in 2.0.0. Use accuracy.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use accuracy.\")\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "# prediction1 = np.array(dtc_predictions.select('prediction').collect())\n",
    "# label = np.array(AirQualityIndex.select('AirQualityIndex').collect())\n",
    "\n",
    "results = rfc_predictions.select(['prediction', 'AirQualityIndex'])\n",
    "predictionAndLabels=results.rdd\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "# Overall statistics\n",
    "recall = metrics.recall()\n",
    "f1Score = metrics.fMeasure()\n",
    "print(\"Recall = %s\" % recall)\n",
    "print(\"F1 Score = %s\" % f1Score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
